{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e12f5311-9ea5-451e-a01c-3c22ddc8bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image, write_jpeg\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import crop\n",
    "\n",
    "import scipy.io as scio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a44dcf1-3798-4c13-b0a9-f16735166b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = np.array(['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion', 'Confidence', 'Disapproval', 'Disconnection',\n",
    "                     'Disquietment', 'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem', 'Excitement', 'Fatigue', 'Fear',\n",
    "                     'Happiness', 'Pain', 'Peace', 'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise', 'Sympathy', 'Yearning'])\n",
    "\n",
    "emotion_encode = {e: i for i, e in enumerate(emotions)}\n",
    "emotion_decode = {i: e for e, i in emotion_encode.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c81ac5-5a04-4a5b-9961-aa05471dc578",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmoticDataset(Dataset):\n",
    "    def __init__(self, subject_size, context_size, anns_dir, img_dir):\n",
    "        anns = scio.loadmat(anns_dir)[\"train\"]\n",
    "        self.anns = np.fromiter(filter(lambda x: x[\"folder\"].item() != \"framesdb/images\", iter(anns[0])), dtype=anns.dtype)\n",
    "        self.img_dir = img_dir\n",
    "        self.subject_transform = transforms.Resize(subject_size)\n",
    "        self.context_transform = transforms.Resize(context_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.anns.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ann = self.anns[idx]\n",
    "\n",
    "        img_loc = \"../data/cvpr_emotic/\" + ann[\"folder\"].item() + '/' + ann[\"filename\"].item()\n",
    "        context_img = read_image(img_loc)\n",
    "        \n",
    "        bbox =  ann[\"person\"][\"body_bbox\"][0][0][0].astype(int)\n",
    "        subject_img = crop(context_img, bbox[1], bbox[0], bbox[3] - bbox[1], bbox[2] - bbox[0])\n",
    "\n",
    "        label = np.zeros(len(emotions), dtype=np.float32)\n",
    "        ems = [i.item() for i in ann[\"person\"][\"annotations_categories\"][0][0].item()[0][0]]\n",
    "        for e in ems:\n",
    "            label[emotion_encode[e]] = 1.\n",
    "\n",
    "        subject_img = self.subject_transform(subject_img.float())\n",
    "        context_img = self.context_transform(context_img.float())\n",
    "\n",
    "        return subject_img, context_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af59d47-7c33-4ef2-8ef7-05765e414d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_size = (50, 50)\n",
    "context_size = (200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5088280b-72bd-41d0-b80b-f3a6f1fa77cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_data = EmoticDataset(subject_size, context_size, \"../data/Annotations/Annotations.mat\", \"../data/cvpr_emotic/\")\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be692383-5210-4ae2-b34c-26c2a2ad1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_branch():\n",
    "    return nn.Sequential(\n",
    "               # nn.Conv2d(3, 96, (11, 1), stride=(4, 1)),\n",
    "               # nn.ReLU(),\n",
    "               # nn.BatchNorm2d(96),\n",
    "               # nn.Conv2d(96, 96, (1, 11), stride=(1, 4)),\n",
    "               # nn.ReLU(),\n",
    "               # nn.BatchNorm2d(96),\n",
    "               # nn.MaxPool2d(3, stride=2),\n",
    "        \n",
    "               nn.Conv2d(3, 256, (1, 5), padding=\"same\"),\n",
    "               nn.ReLU(),\n",
    "               nn.BatchNorm2d(256),\n",
    "               nn.Conv2d(256, 256, (5, 1), padding=\"same\"),\n",
    "               nn.ReLU(),\n",
    "               nn.BatchNorm2d(256),\n",
    "               nn.MaxPool2d(3, stride=2),\n",
    "        \n",
    "               nn.Conv2d(256, 384, (1, 3), padding=\"same\"),\n",
    "               nn.ReLU(),\n",
    "               nn.BatchNorm2d(384),\n",
    "               nn.Conv2d(384, 384, (3, 1), padding=\"same\"),\n",
    "               nn.ReLU(),\n",
    "               nn.BatchNorm2d(384),\n",
    "               \n",
    "               nn.Conv2d(384, 384, (1, 3), padding=\"same\"),\n",
    "               nn.ReLU(),\n",
    "               nn.BatchNorm2d(384),\n",
    "               nn.Conv2d(384, 384, (3, 1), padding=\"same\"),\n",
    "               nn.ReLU(),\n",
    "               nn.BatchNorm2d(384),\n",
    "    \n",
    "               nn.Conv2d(384, 256, (1, 3), padding=\"same\"),\n",
    "               nn.ReLU(),\n",
    "               nn.BatchNorm2d(256),\n",
    "               nn.Conv2d(256, 256, (3, 1), padding=\"same\"),\n",
    "               nn.ReLU(),\n",
    "               nn.BatchNorm2d(256),\n",
    "               nn.MaxPool2d(3, stride=2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "002904bb-cc8f-4ea4-8c81-7959c3a0ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.subject = net_branch()\n",
    "        self.context = net_branch()\n",
    "        \n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(645632, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, len(emotions)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, s, c):\n",
    "        s = self.subject(s)\n",
    "        s = torch.flatten(s, start_dim=1)\n",
    "        \n",
    "        c = self.context(c)\n",
    "        c = torch.flatten(c, start_dim=1)\n",
    "\n",
    "        x = torch.cat((s, c), dim=1)\n",
    "        x = self.fusion(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b69484bb-4517-4aa8-97fd-d17061318a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotic_net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b34afa7-edb4-4ec7-a532-1cfd0a7020b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.399846  [    0/12915]\n",
      "loss: 0.315113  [   16/12915]\n",
      "loss: 0.405735  [   32/12915]\n",
      "loss: 0.824355  [   48/12915]\n",
      "loss: 0.539643  [   64/12915]\n",
      "loss: 0.383517  [   80/12915]\n",
      "loss: 0.489162  [   96/12915]\n",
      "loss: 0.273486  [  112/12915]\n",
      "loss: 0.449190  [  128/12915]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m pred \u001b[38;5;241m=\u001b[39m emotic_net(S, C)\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.venv/torch/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/torch/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/torch/lib/python3.10/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "size = len(train_dataloader.dataset)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(emotic_net.parameters(), lr=.01)\n",
    "\n",
    "emotic_net.train()\n",
    "for batch, (S, C, y) in enumerate(train_dataloader):\n",
    "    pred = emotic_net(S, C)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss, current = loss.item(), batch * batch_size\n",
    "    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b011ff-2e56-4da8-ac1d-6f71b806fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32373e38-3afe-42ee-a2a0-d2aecd7ac194",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = n(data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fea0891-ae49-4314-a97d-db3ca1674bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 200, 200])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8ead55-284e-4eb2-91d3-156db0c7edd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 26])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "144f6b92-8925-4790-a150-1fef40303f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49a83741-bdd7-424b-bcb4-dba63150cc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5eb78ae-fa57-4cfa-8750-1d31febfc3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5698, 0.7862, 0.7664, 0.6679, 0.5959, 0.7587, 0.7810, 0.5231, 0.5032,\n",
       "         0.6645, 0.7654, 0.5479, 0.6572, 0.7612, 0.7904, 0.7040, 0.7348, 0.6104,\n",
       "         0.5603, 0.6832, 0.6952, 0.9693, 0.5510, 0.5029, 0.7823, 0.6094],\n",
       "        [0.5439, 0.5876, 0.2667, 1.1274, 0.3508, 0.7186, 1.2768, 1.1940, 0.8091,\n",
       "         0.8100, 0.5317, 0.5784, 0.4584, 0.8248, 0.5248, 0.4268, 0.8264, 0.4869,\n",
       "         0.3836, 1.1287, 0.8039, 0.8637, 0.5582, 0.3649, 0.9937, 0.5323],\n",
       "        [0.5015, 0.4972, 0.6327, 0.6324, 0.5582, 0.7617, 0.6780, 0.7400, 0.4364,\n",
       "         0.7839, 0.6695, 0.9016, 0.5458, 0.8100, 0.7402, 0.6117, 0.6556, 0.7592,\n",
       "         0.4259, 0.6794, 0.7276, 0.7482, 0.5616, 0.4885, 1.0681, 0.6824],\n",
       "        [0.6377, 0.4700, 0.4240, 0.6734, 0.8766, 0.8690, 0.7802, 0.6464, 0.5150,\n",
       "         0.4866, 0.6999, 0.5250, 0.6585, 0.7404, 0.8748, 0.6310, 0.5452, 0.5402,\n",
       "         0.6032, 0.7431, 0.7918, 0.9087, 0.7571, 0.4751, 0.8918, 0.8567],\n",
       "        [0.4619, 0.4957, 0.6861, 0.7400, 0.6055, 0.6578, 0.8895, 0.8161, 0.4428,\n",
       "         0.8060, 0.6497, 0.6061, 0.6045, 0.8630, 0.6732, 0.5058, 0.7686, 0.8174,\n",
       "         0.4803, 0.7612, 0.8451, 0.9152, 0.7482, 0.5367, 0.7782, 0.6217],\n",
       "        [0.6136, 0.6335, 0.5584, 0.7305, 0.5484, 0.7986, 0.9737, 0.6004, 0.4801,\n",
       "         0.8198, 0.7613, 0.6315, 0.8847, 0.5582, 0.9845, 0.6045, 0.6432, 0.6245,\n",
       "         0.9040, 1.0086, 0.4831, 0.8532, 0.5858, 0.6800, 1.0222, 0.6841],\n",
       "        [0.3001, 0.5130, 0.4806, 0.7101, 0.2829, 1.5689, 0.7586, 0.7102, 0.3238,\n",
       "         0.4967, 1.0340, 0.6655, 0.5602, 0.4970, 1.7538, 0.1765, 1.0409, 0.4414,\n",
       "         0.4418, 0.7045, 1.0798, 1.0842, 0.5805, 0.1792, 0.8472, 0.3433],\n",
       "        [0.5432, 0.6331, 0.5322, 0.8405, 0.5413, 0.9412, 1.0946, 0.8096, 0.6469,\n",
       "         0.7691, 0.9862, 0.7016, 0.6783, 0.8250, 0.8813, 0.5030, 0.6048, 0.5187,\n",
       "         0.8344, 0.6710, 0.7958, 0.5473, 0.6167, 0.5760, 0.8468, 0.5807],\n",
       "        [0.5335, 0.5013, 0.6264, 0.8875, 0.6269, 0.6244, 0.6859, 0.8445, 0.5522,\n",
       "         0.7061, 0.6308, 0.9802, 0.7888, 0.7473, 0.5460, 0.5365, 0.7157, 0.6359,\n",
       "         0.5859, 0.5543, 0.6293, 0.6702, 0.9478, 0.7058, 0.7108, 0.4511],\n",
       "        [0.5655, 0.6144, 0.5213, 0.5292, 0.4668, 0.9351, 0.9280, 0.7090, 0.4774,\n",
       "         0.5379, 0.7996, 0.4575, 0.6054, 0.8541, 0.7407, 0.6639, 0.5693, 0.5490,\n",
       "         0.3944, 0.5656, 0.5624, 0.7310, 0.6874, 0.6509, 0.8666, 0.6389],\n",
       "        [0.5100, 0.8450, 0.6776, 0.7400, 0.4239, 0.5657, 1.1419, 0.8727, 0.5456,\n",
       "         0.6475, 0.7988, 0.7146, 0.5835, 0.5456, 0.7787, 0.4972, 0.8244, 0.7236,\n",
       "         0.3692, 0.5618, 0.8200, 0.4242, 0.7663, 0.4456, 1.4376, 0.6559],\n",
       "        [0.7790, 0.6760, 0.5971, 0.5584, 0.6042, 1.0170, 0.7874, 0.6555, 0.4622,\n",
       "         1.2283, 0.6535, 0.9818, 0.4329, 0.5144, 0.6991, 0.6438, 0.8555, 0.5637,\n",
       "         0.3971, 0.7105, 0.8742, 0.7279, 0.7112, 0.5006, 1.3608, 0.5100],\n",
       "        [0.3160, 0.3972, 0.4559, 1.1604, 0.9484, 0.6870, 0.9222, 0.9524, 0.4614,\n",
       "         0.8852, 0.7509, 0.8882, 0.7184, 0.7220, 0.9691, 0.7235, 0.7936, 0.4344,\n",
       "         0.3992, 0.5614, 0.5648, 0.9380, 0.6471, 0.5170, 0.7628, 0.5624],\n",
       "        [0.6859, 0.5408, 0.4845, 0.5855, 0.7448, 0.5873, 0.8355, 0.6424, 0.5336,\n",
       "         0.7677, 0.7254, 0.5130, 0.9240, 0.8396, 0.7771, 0.7871, 0.6462, 0.6000,\n",
       "         0.4638, 0.8267, 0.5155, 0.9084, 0.9816, 0.4536, 0.7317, 0.7226],\n",
       "        [0.4682, 0.5846, 0.5097, 0.6473, 0.7453, 0.6310, 0.8013, 0.6275, 0.4572,\n",
       "         0.6582, 0.7359, 0.7332, 0.4979, 0.7644, 1.0065, 0.5109, 0.6433, 0.6390,\n",
       "         0.4642, 1.0372, 0.5262, 0.8348, 0.8352, 0.6282, 0.8881, 0.7780],\n",
       "        [0.5199, 0.6258, 0.6290, 0.7309, 0.5268, 0.7454, 0.7320, 0.5775, 0.5209,\n",
       "         0.6284, 0.5876, 0.5815, 0.5610, 0.8750, 0.8511, 0.6614, 0.7355, 0.6391,\n",
       "         0.4800, 0.6774, 0.5811, 0.8932, 0.7141, 0.5926, 1.1270, 0.7248]],\n",
       "       grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(out, data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c91576bc-2ec0-423b-9dd3-1930e06ab550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Affection', 'Fatigue', 'Happiness', 'Sensitivity'], dtype='<U15')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(emotions)[out[0] > 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7f46ce3-818b-4280-ba34-dced46f1fb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning'],\n",
       "       ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion',\n",
       "        'Confidence', 'Disapproval', 'Disconnection', 'Disquietment',\n",
       "        'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem',\n",
       "        'Excitement', 'Fatigue', 'Fear', 'Happiness', 'Pain', 'Peace',\n",
       "        'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise',\n",
       "        'Sympathy', 'Yearning']], dtype='<U15')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.broadcast_to(emotions, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2389e9a6-b259-4fda-a500-0207ad5934da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype='<U15')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 9\n",
    "thres = 0.7\n",
    "\n",
    "emotions[out[idx] > thres]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
